{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from __future__ import print_function\n",
    "import os, sys, glob, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdir=\"/home/ubuntu/nbs/courses/deeplearning1/nbs/data/statefarm/\"\n",
    "dosetup=0\n",
    "\n",
    "ddir=bdir\n",
    "#ddir=bdir + \"/sample/\"\n",
    "sdir=bdir + \"/sample/\"\n",
    "trdir=ddir + \"/train/\"\n",
    "tedir=ddir + \"/test/\"\n",
    "vdir=ddir + \"/valid/\"\n",
    "rdir=ddir + \"/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def moveallimages(src, pattern, dest):\n",
    "    imgs=glob.glob(src + \"/\" + pattern)\n",
    "    for img in imgs:\n",
    "        os.rename(img, dest + \"/\" + os.path.basename(img))\n",
    "\n",
    "# Function to copy/move nimages random images from 'src' to 'dest'.\n",
    "from shutil import copyfile        \n",
    "def moverandimages(src, nimages, dest, docopy=0):\n",
    "    imgs=glob.glob(src + \"/\" + \"*.jpg\")\n",
    "    shuff = np.random.permutation(imgs)\n",
    "    for i in range(nimages):\n",
    "        if (docopy == 0):\n",
    "            os.rename(shuff[i], dest + \"/\" + os.path.basename(shuff[i]))\n",
    "        else:\n",
    "            copyfile(shuff[i], dest + \"/\" + os.path.basename(shuff[i]))\n",
    "\n",
    "if (dosetup == 1):\n",
    "    for c in range(10):\n",
    "        cdir=\"c%d\" %c\n",
    "        # Create validation set with 100 images from each class\n",
    "        moverandimages(trdir + \"/\" + cdir, 100, vdir + \"/\" + cdir)\n",
    "        # Create sample training set with 100 images from each class\n",
    "        moverandimages(trdir + \"/\" + cdir, 100, sdir + \"/train/\" + cdir, docopy=1)\n",
    "        # Create sample validation set with 50 images from each class\n",
    "        moverandimages(trdir + \"/\" + cdir, 50, sdir + \"/valid/\" + cdir, docopy=1)\n",
    "    \n",
    "    # Create sample test set with 4000 random images\n",
    "    moverandimages(tedir + \"/unknown/\", 4000, sdir + \"/test/unknown/\", docopy=1)        \n",
    "    print(\"Setup Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with VGG16 finetuned for 10 class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16\n",
    "vgg=Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_batch=utils.get_batches(trdir)\n",
    "val_batch=utils.get_batches(vdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.finetune(trn_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.fit(trn_batch, val_batch, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a convolution model based on 'more filters and larger convolution kernel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3, 224, 224)),\n",
    "            Convolution2D(32, 3, 3, border_mode='same', activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D(border_mode='same'),\n",
    "            Convolution2D(64, 3, 3, border_mode='same', activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D(border_mode='same'),\n",
    "            Convolution2D(128, 3, 3, border_mode='same', activation='relu'),\n",
    "            BatchNormalization(axis=1)\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            BatchNormalization(),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "cm.summary()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_batch=utils.get_batches(trdir, batch_size=8)\n",
    "val_batch=utils.get_batches(vdir, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm.fit_generator(trn_batch, trn_batch.N, nb_epoch=5, validation_data=val_batch, nb_val_samples=val_batch.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 with dense layer finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16\n",
    "vgg=Vgg16()\n",
    "vm = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_layers_idx=[i for (i, l) in enumerate(vm.layers) if type(l)==Convolution2D] # all convolution layers\n",
    "last_conv_layer=conv_layers_idx[-1]\n",
    "conv_layers=vm.layers[:last_conv_layer+1] # All layers upto last convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvm=Sequential(conv_layers)  # VGG model with convolution layers\n",
    "cvm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_batch=utils.get_batches(trdir, batch_size=128, shuffle=False)\n",
    "val_batch=utils.get_batches(vdir, batch_size=128, shuffle=False)\n",
    "tst_batch=utils.get_batches(tedir, batch_size=128, shuffle=False)\n",
    "\n",
    "trn_features = cvm.predict_generator(trn_batch, trn_batch.nb_sample)\n",
    "val_features = cvm.predict_generator(val_batch, val_batch.nb_sample)\n",
    "tst_features = cvm.predict_generator(tst_batch, tst_batch.nb_sample)\n",
    "\n",
    "utils.save_array(rdir + \"cvm_train_features.dat\", trn_features)\n",
    "utils.save_array(rdir + \"cvm_val_features.dat\", val_features)\n",
    "utils.save_array(rdir + \"cvm_test_features.dat\", tst_features)\n",
    "utils.save_array(rdir + \"cvm_train_labels.dat\", trn_batch.classes)\n",
    "utils.save_array(rdir + \"cvm_val_labels.dat\", val_batch.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load saved features that were output by convolution layers of vgg model\n",
    "trn_features = utils.load_array(rdir + \"cvm_train_features.dat\")\n",
    "val_features = utils.load_array(rdir + \"cvm_val_features.dat\")\n",
    "#tst_features = utils.load_array(rdir + \"cvm_test_features.dat\") # Causes memory overrun, load this just before predict\n",
    "trn_labels = utils.load_array(rdir + \"cvm_train_labels.dat\")\n",
    "val_labels = utils.load_array(rdir + \"cvm_val_labels.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fvm = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "fvm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fvm.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fvm.fit(trn_features, utils.onehot(trn_labels), batch_size=64, nb_epoch=5, \n",
    "        validation_data=(val_features,utils.onehot(val_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fvm.save_weights(rdir + \"fvm_wts.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_features = utils.load_array(rdir + \"cvm_test_features.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explicitly free some memory corresponding to unused variables\n",
    "del(trn_features)\n",
    "del(trn_labels)\n",
    "del(val_features)\n",
    "del(val_labels)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fvm_pred = fvm.predict(tst_features, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils.save_array(rdir + \"fvm_pred.dat\", fvm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst_batch=utils.get_batches(tedir, batch_size=128, shuffle=False)\n",
    "trn_batch=utils.get_batches(trdir, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnames=tst_batch.filenames\n",
    "imgs = np.array([f[8:] for f in fnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fvm_pred = np.clip(fvm_pred, 0.03, 0.97)\n",
    "subm = pd.DataFrame(fvm_pred, columns=sorted(trn_batch.class_indices, key=trn_batch.class_indices.get))\n",
    "subm.insert(0, 'img', imgs)\n",
    "subm.to_csv(rdir + \"fvm_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG with data augmentation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
