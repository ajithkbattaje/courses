{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from keras.layers import Input, Dense, Activation,  Flatten, Dropout, Lambda, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from resnet50 import Resnet50\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdir=\"/home/ubuntu/nbs/courses/deeplearning1/nbs/data/fishery/\"\n",
    "trdir=bdir + \"train/\"\n",
    "tedir=bdir + \"test_stg1/\"\n",
    "vdir = bdir + \"valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "??utils.get_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### One time setup to move random train images into validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def moveallimages(src, pattern, dest):\n",
    "    imgs=glob.glob(src + \"/\" + pattern)\n",
    "    for img in imgs:\n",
    "        os.rename(img, dest + \"/\" + os.path.basename(img))\n",
    "\n",
    "# Function to copy/move nimages random images from 'src' to 'dest'.\n",
    "from shutil import copyfile        \n",
    "def moverandimages(src, nimages, dest, docopy=0):\n",
    "    imgs=glob.glob(src + \"/\" + \"*.jpg\")\n",
    "    shuff = np.random.permutation(imgs)\n",
    "    for i in range(nimages):\n",
    "        if (docopy == 0):\n",
    "            os.rename(shuff[i], dest + \"/\" + os.path.basename(shuff[i]))\n",
    "        else:\n",
    "            copyfile(shuff[i], dest + \"/\" + os.path.basename(shuff[i]))\n",
    "            \n",
    "# Create directories in valid directory similar to train directory followed by copying images\n",
    "for src in glob.glob(trdir + \"/*\"):\n",
    "    dest=vdir + os.path.basename(src)\n",
    "    os.mkdir(dest)\n",
    "    moverandimages(src, 25, dest, docopy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analyse training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class=DOL imgsz= [(1280, 974), (1280, 720), (1280, 750)]\n",
      "class=YFT imgsz= [(1280, 750), (1244, 700), (1192, 670), (1280, 720), (1276, 718), (1280, 974), (1518, 854), (1280, 924)]\n",
      "class=BET imgsz= [(1280, 974), (1244, 700), (1192, 670), (1280, 720), (1276, 718), (1280, 750), (1518, 854)]\n",
      "class=LAG imgsz= [(1280, 720)]\n",
      "class=OTHER imgsz= [(1280, 750), (1280, 720), (1280, 974)]\n",
      "class=NoF imgsz= [(1280, 750), (1244, 700), (1732, 974), (1334, 750), (1192, 670), (1280, 720), (1276, 718), (1518, 854)]\n",
      "class=ALB imgsz= [(1280, 974), (1244, 700), (1192, 670), (1280, 720), (1276, 718), (1280, 750), (1518, 854), (1280, 924)]\n",
      "class=SHARK imgsz= [(1280, 750), (1280, 720), (1280, 974)]\n"
     ]
    }
   ],
   "source": [
    "import PIL, glob\n",
    "\n",
    "classes = [os.path.basename(f) for f in glob.glob(trdir + \"/*\")]\n",
    "for c in classes:\n",
    "    imgsz = [PIL.Image.open(f).size for f in glob.glob(trdir + \"/\" + c + \"/*\")] \n",
    "    uniqimgsz = list(set(imgsz))\n",
    "    print(\"class=\" + c + \" imgsz=\", uniqimgsz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features from Resnet without last FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm = Resnet50(size=(640, 360), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n",
      "Found 200 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_batches = utils.get_batches(trdir, target_size=(640, 360), shuffle=False)\n",
    "val_batches = utils.get_batches(vdir, target_size=(640, 360), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_features = rm.model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = rm.model.predict_generator(trn_batches, trn_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.save_array(bdir + \"/results/resnet_val_640_360.dat\", val_features)\n",
    "utils.save_array(bdir + \"/results/resnet_trn_640_360.dat\", trn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_labels = utils.onehot(val_batches.classes)\n",
    "trn_labels = utils.onehot(trn_batches.classes)\n",
    "utils.save_array(bdir + \"/results/resnet_val_labels_640_360.dat\", val_labels)\n",
    "utils.save_array(bdir + \"/results/resnet_trn_labels_640_360.dat\", trn_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load convolution features from disk in case it was generated in a previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_features = utils.load_array(bdir + \"/results/resnet_val_640_360.dat\")\n",
    "trn_features = utils.load_array(bdir + \"/results/resnet_trn_640_360.dat\")\n",
    "val_labels = utils.load_array(bdir + \"/results/resnet_val_labels_640_360.dat\")\n",
    "trn_labels = utils.load_array(bdir + \"/results/resnet_trn_labels_640_360.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classifier for resnet convolution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "i = Input(shape=rm.model.output_shape[1:])\n",
    "\n",
    "l = GlobalAveragePooling2D(input_shape=rm.model.output_shape[1:])(i)\n",
    "l = Dense(2048, activation='relu')(l)\n",
    "l = BatchNormalization()(l)\n",
    "l = Dropout(0.5)(l)\n",
    "l = Dense(1024, activation='relu')(l)\n",
    "l = BatchNormalization()(l)\n",
    "l = Dropout(0.5)(l)\n",
    "l = Dense(8, activation='softmax')(l)\n",
    "m = Model(input=i, output=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 2048, 20, 12)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_14 (Global(None, 2048)          0           input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 2048)          4196352     globalaveragepooling2d_14[0][0]  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorma(None, 2048)          4096        dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 2048)          0           batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 1024)          2098176     dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorma(None, 1024)          2048        dense_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 1024)          0           batchnormalization_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 8)             8200        dropout_9[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6308872\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.compile(optimizer=Adam(1e-4), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3777 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0726 - acc: 0.9780 - val_loss: 0.0112 - val_acc: 0.9950\n",
      "Epoch 2/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0783 - acc: 0.9735 - val_loss: 0.0267 - val_acc: 0.9900\n",
      "Epoch 3/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0743 - acc: 0.9778 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0662 - acc: 0.9793 - val_loss: 0.0066 - val_acc: 0.9950\n",
      "Epoch 5/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0638 - acc: 0.9767 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0583 - acc: 0.9801 - val_loss: 0.0086 - val_acc: 0.9950\n",
      "Epoch 7/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0731 - acc: 0.9759 - val_loss: 0.0417 - val_acc: 0.9850\n",
      "Epoch 8/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0716 - acc: 0.9764 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0762 - acc: 0.9786 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "3777/3777 [==============================] - 4s - loss: 0.0578 - acc: 0.9793 - val_loss: 0.0111 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fd7536e90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.optimizer.lr = 1e-5\n",
    "m.fit(trn_features, trn_labels, batch_size=64, nb_epoch=10, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.save_weights(bdir + \"/results/resnet_3layer_dense_20epoch_dropout_weights.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "tst_batches=utils.get_batches(tedir, target_size=(640, 360), shuffle=False)\n",
    "tst_conv_features = rm.model.predict_generator(tst_batches, tst_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst_labels = m.predict(tst_conv_features, batch_size=128)\n",
    "tst_labels = np.clip(tst_labels, 0.01, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class_labels=sorted(trn_batches.class_indices)\n",
    "results = pd.DataFrame(columns=class_labels, data=tst_labels)\n",
    "bfnames = [f[8:] for f in tst_batches.filenames]\n",
    "results.insert(0, 'image', bfnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(bdir + \"submission_640_360_resnet_3lrd_dropout_99clip.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
